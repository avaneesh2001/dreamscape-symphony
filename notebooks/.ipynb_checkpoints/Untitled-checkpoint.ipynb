{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0f31987-2067-4bb9-b9c1-13a22c5ef790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51007547-7ed5-4182-9355-d827b3cbb5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\avane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\avane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import pipeline\n",
    "from typing import List, Tuple\n",
    "from sklearn.decomposition import NMF\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "class DreamAnalyzer():    \n",
    "    def __init__(self):\n",
    "        self.ner_pipeline = pipeline(model = \"dbmdz/bert-large-cased-finetuned-conll03-english\",grouped_entities = True)\n",
    "        self.sentiment_pipeline = pipeline(model = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "        self.vectorizer = TfidfVectorizer(stop_words='english',max_features=5000)\n",
    "\n",
    "    \n",
    "    def extract_named_entity(self, text: str) -> List[str]:\n",
    "        entities = self.ner_pipeline(text)\n",
    "        themes = [entity['word'] for entity in entities]\n",
    "        unique_themes = list(set(themes))\n",
    "        return unique_themes\n",
    "    \n",
    "    def analyze_sentiment(self, text: str) -> Tuple[str, float]:\n",
    "        sentiment = self.sentiment_pipeline(text)[0]\n",
    "        emotion = sentiment['label']\n",
    "        score = sentiment['score']\n",
    "        return emotion, score\n",
    "\n",
    "    def extract_keywords(self, text: List[str], num_keywords: int = 10) -> List[str]:\n",
    "        tfidf_matrix = self.vectorizer.fit_transform(text)\n",
    "        feature_names = self.vectorizer.get_feature_names_out()\n",
    "        scores = np.asarray(tfidf_matrix.sum(axis=0)).ravel()\n",
    "        feature_names = self.vectorizer.get_feature_names_out()\n",
    "        keyword_scores = dict(zip(feature_names, scores))\n",
    "        sorted_keywords = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        top_keywords = [keyword for keyword, score in sorted_keywords[:num_keywords]]\n",
    "        return top_keywords\n",
    "    \n",
    "    def get_themes(self,text:List[str]) :\n",
    "        if not hasattr(self.vectorizer, 'vocabulary_'):\n",
    "            self.vectorizer.fit(text)\n",
    "        num_topics = 2\n",
    "        tfidf_matrix = self.vectorizer.transform(text)\n",
    "        nmf_model = NMF(n_components=num_topics, init='random', random_state=42)\n",
    "        nmf_matrix = nmf_model.fit_transform(tfidf_matrix)\n",
    "        feature_names = np.array(self.vectorizer.get_feature_names_out())\n",
    "        top_feature_indices = np.argsort(nmf_model.components_, axis=1)[:, -num_words:]\n",
    "        top_features = [list(feature_names[indices]) for indices in top_feature_indices]\n",
    "        return top_features\n",
    "    \n",
    "    def analyze_dream(self, text: str) -> Tuple[List[str], Tuple[str, float], List[str], List[List[str]]]:\n",
    "        named_entity = self.extract_named_entity(text)\n",
    "        sentiment = self.analyze_sentiment(text)\n",
    "        document = sent_tokenize(text)\n",
    "        keywords = self.extract_keywords(document)\n",
    "        themes = self.get_themes(document)\n",
    "        return named_entity, sentiment, keywords, themes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a4a8dc0b-28dc-4771-bc7b-003e94e84608",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "D:\\Program Files\\miniconda\\envs\\dreamscape-symphony\\Lib\\site-packages\\transformers\\pipelines\\token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dream_analyser  = DreamAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6fc01e3-a68d-4014-8198-73d3bbabaf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dream = \"I dreamt about flying in the sky with Navi  The ocean was calm, and the sun was shining.felt a sense of freedom while soaring above the clouds    There were strange creatures in the forest.I was exploring an ancient castle.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "492b2703-443b-4d7a-9ade-8daee69da27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\miniconda\\envs\\dreamscape-symphony\\Lib\\site-packages\\sklearn\\decomposition\\_nmf.py:136: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(res * 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Navi'],\n",
       " ('POSITIVE', 0.999600350856781),\n",
       " ['ancient',\n",
       "  'calm',\n",
       "  'castle',\n",
       "  'clouds',\n",
       "  'creatures',\n",
       "  'dreamt',\n",
       "  'exploring',\n",
       "  'felt',\n",
       "  'flying',\n",
       "  'forest'],\n",
       " array([['sense', 'clouds', 'exploring', 'strange', 'castle', 'freedom',\n",
       "         'flying', 'dreamt', 'forest', 'navi'],\n",
       "        ['sun', 'ocean', 'calm', 'creatures', 'ancient', 'soaring',\n",
       "         'felt', 'shining', 'sky', 'navi']], dtype=object))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dream_analyser.analyze_dream(dream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18633502-1089-4be2-831e-fa47b0ae77e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d3e913-a60f-4114-b7b1-20c4999c6702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
